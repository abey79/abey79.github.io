[{"content":"Often, technical documentations include lists or other snippets of text that are strongly related to some of the project\u0026rsquo;s code. vpype\u0026rsquo;s documentation is no exception to this.\nFor instance, the Built-in symbols section lists the units available to expressions:\nThese units are related to the following piece of code:\n# vpype/utils.py UNITS = { \u0026#34;px\u0026#34;: 1.0, \u0026#34;in\u0026#34;: 96.0, \u0026#34;inch\u0026#34;: 96.0, \u0026#34;ft\u0026#34;: 12.0 * 96.0, \u0026#34;yd\u0026#34;: 36.0 * 96.0, \u0026#34;mi\u0026#34;: 1760.0 * 36.0 * 96.0, \u0026#34;mm\u0026#34;: 96.0 / 25.4, \u0026#34;cm\u0026#34;: 96.0 / 2.54, \u0026#34;m\u0026#34;: 100.0 * 96.0 / 2.54, \u0026#34;km\u0026#34;: 100_000.0 * 96.0 / 2.54, \u0026#34;pc\u0026#34;: 16.0, \u0026#34;pt\u0026#34;: 96.0 / 72.0, } I recently added support for more units and, of course, the documentation was at risk of running out of sync. Obviously, generating the list of units based on the code would be a better solution. After some Googling, here is how I did it.\nThe basic idea is to use substitutions. A substitution consists of assigning a text snippet to a keyword, and subsequently use said keyword (with the |keyword| syntax) in the documentation\u0026rsquo;s body. The second insight is to use the rst_prolog variable (within the conf.py file) for the definition. This being regular Python, the definition can easily be auto-generated based on the original code.\nHere is how it looks for the case above:\n# docs/conf.py import vpype as vp # [...] UNIT_STRINGS = \u0026#34;, \u0026#34;.join(f\u0026#34;``{s}``\u0026#34; for s in sorted(vp.UNITS.keys()) if s is not \u0026#34;in\u0026#34;) rst_prolog = f\u0026#34;\u0026#34;\u0026#34; .. |units| replace:: {UNIT_STRINGS}\u0026#34;\u0026#34;\u0026#34; (Note that in is explicitly excluded from the list because it is a reserved Python keyword and cannot be used in the context of vpype expressions.)\nAnd this is how the substitution is used in the actual documentation file:\n.. docs/fundamentals.rst * Units constants (|units|). These variables may be used to convert values to CSS pixels unit, which *vpype* uses internally. For example, the expression ``%(3+4)*cm%`` evaluates to the pixel equivalent of 7 centimeters (e.g. ~264.6 pixels). (Note that expressions may overwrite these variables, e.g. to use the ``m`` variable for another purpose.)Et voilà! Nice and easy. I certainly expect to use this technique often in the future.\n","permalink":"https://bylr.info/articles/2022/09/30/til-sphinx-substitutions/","summary":"Often, technical documentations include lists or other snippets of text that are strongly related to some of the project\u0026rsquo;s code. vpype\u0026rsquo;s documentation is no exception to this.\nFor instance, the Built-in symbols section lists the units available to expressions:\nThese units are related to the following piece of code:\n# vpype/utils.py UNITS = { \u0026#34;px\u0026#34;: 1.0, \u0026#34;in\u0026#34;: 96.0, \u0026#34;inch\u0026#34;: 96.0, \u0026#34;ft\u0026#34;: 12.0 * 96.0, \u0026#34;yd\u0026#34;: 36.0 * 96.0, \u0026#34;mi\u0026#34;: 1760.0 * 36.","title":"TIL: using Sphinx substitutions to generate text snippets from code"},{"content":"This release further solidifies the block commands which were overhauled in vpype 1.9. It also introduces several changes revolving around the \u0026ldquo;plotting with paint\u0026rdquo; use-case, which typically requires the brush to be regularly dipped in a paint well. This can be achieved by inserting \u0026ldquo;dipping\u0026rdquo; patterns at regular intervals determined by the cumulative drawing distance. vpype 1.11 makes this process much easier.\nThanks a lot to Andee Collard for his useful feedback and providing this article\u0026rsquo;s banner!\nPainting with a plotter  Added the splitdist command to split layers by drawing distance (thanks to @LoicGoulefert) (#487, #501)   The new splitdist command, contributed by Loïc Goulefert (thanks a lot!), is the core of the paint plotting use-case. It splits each layer into newly created layers such that their respective drawing distance is each below the specified limit.\nThis command could readily be used with a clever vpype-gcode profile that implements the dipping mechanism at the beginning of each layer. Alternatively, it can be combined with the forlayer block command to insert dipping patterns into the line work. We\u0026rsquo;ll see an example of such a pipeline below.\n Added meters (m) and feet (ft) to the supported units (#498, #508) Fixed an issue with expressions where some variable names corresponding to units (e.g. m) could not be used (expressions may now reuse these names) (#506)   These are rather large units for typical plotting workflow, but come in useful for specifying the maximum drawing distance with splitdist.\nAs a reminder, units are available in two contexts:\n Every time a command accepts a length-type argument or option (e.g. translate 5mm 3cm or linemerge --tolerance 0.05mm). In expressions (e.g. forlayer translate \u0026quot;%_i*3*cm%\u0026quot; 0 end).  In the latter case, the existence of the unit constant precluded the use of variables with the same name. This issue worsened with the addition of m as this is a rather common variable name (e.g. this cookbook recipe uses it). To address this, they are no longer read-only and may now be overwritten. Of course, doing so renders their original value unavailable in the pipeline\u0026rsquo;s subsequent expressions.\n Fixed an issue with blocks where certain nested commands could lead totally unexpected results (#506) API: removed the faulty temp_document() context manager from vpype_cli.State() (#506)   The improved blocks introduced in vpype 1.9 had a major flaw which could, in some circumstances, result in erratic results. It turns out that the new splitdist command triggered this issue and brought it in the spotlight. This is now fixed, and the vpype_cli.State.temp_document() API is a casualty of this patch (luckily, it was introduced recently and I\u0026rsquo;m pretty sure no one used it yet besides me).\n Fixed an issue with the lmove command where order would not be respected in certain cases such as lmove all 2 (the content of layer 2 was placed before that of layer 1) (#506)   This is yet another issue highlighted by to the \u0026ldquo;plotting with paint\u0026rdquo; workflow. When the source layers included the destination layer (as is the case for lmove all 2), the order of the source layers would not be respected (e.g. for a 3-layer pipeline and thelmove all 2 command, layer 2 would end up with its original content, then layer 1, then layer 3). With this fix, the destination layer will now include the source layers' content in the correct order (e.g. in the previous example, layer 2 would end up with the content of layer 1, then layer 2, then layer 3).\n Collectively, these changes enable the \u0026ldquo;plotting with paint\u0026rdquo; workflow using the following pipeline:\n$ vpype \\  read input.svg \\  forlayer \\  lmove %_lid% 1 \\  splitdist 1m \\  forlayer \\  lmove %_lid% \u0026#34;%_lid*2%\u0026#34; \\  read -l \u0026#34;%_lid*2-1%\u0026#34; dip_%_name%.svg \\  end \\  lmove all %_lid% \\  name -l %_lid% %_name% \\  color -l %_lid% %_color% \\  end \\  write output.svg For this to work, the layers in input.svg must be named after their respective color and, for each such color, a file named dip_COLORNAME.svg must exist. For example, if input.svg has two layers named \u0026ldquo;red\u0026rdquo; and \u0026ldquo;blue\u0026rdquo;, then the dip_red.svg and dip_blue.svg files must exist.\nThe following figure illustrates the results for synthetic data.\n (left) Input SVG with 3 layers. (middle) The three corresponding dipping pattern SVGs. (right) The output SVG with 3 layers and the visible dipping patterns interspersed within the line work.\n  This pipeline is listed in a cookbook recipe and will be explained in details, along with the forlayer block command, in a future article.\nOther changes  Improved the linemerge algorithm by making it less dependent on line order (#496)   The linemerge command is implemented using a greedy algorithm which roughly works as follows:\n Pick the first available line. Look for another line that can be appended. If found, merge both lines and look for further line to append (back to step 2). If not, save the current line, pick the next available one, and repeat (back to step 1).  By default, linemerge always considers both endings of each line, possibly reversing them if this enables a merge. This is not always desirable though, which is why the --no-flip option exists. In this case, the algorithm would only try to append to the current line, without trying to prepend as well. This oversight led to a greater dependence on line order and, occasionally, suboptimal results, as illustrated by the figure below.\n  (left) Initial situation. (middle) Result when both appending only. (right) Results when appending and prepending.\n  With this fix, linemerge --no-flip now tries to both append and prepend, leading to more consistent results.\n Added --keep-page-size option to grid command (#506)   By default, the grid block command sets the page size to its geometry. For example, the block grid --offset 4cm 3cm 3 5 [...] end sets the page size to 12x15cm. This behaviour can now be disabled with the --keep-page-size option.\nThis change mainly helps for the testability of the blocks feature (in this release, I\u0026rsquo;ve added multiple tests to minimise the risk of future regression), but I figured it could have its occasional use out there.\n Added HPGL configurations for the Houston Instrument DMP-161, HP7550, Roland DXY 1xxxseries and sketchmate plotters (thanks to @jimmykl and @ithinkido) (#472, #474)   Thanks a lot, Jimmy Kirkus-Lamont and @ithinkido! ❤️\n Added equality operator to vpype.LineCollection and vpype.Document (#506)   I can now check if two layers or documents have the same content and metadata using the equality operator ==. This is immensely useful when writing tests. I have no idea why it took so long… 🤷\n Pinned Shapely to 1.8.2, which is the first release in a long time to have binaries for most platforms/Python release combination (including Apple-silicon Macs and Python 3.10) (#475)   It was quite the roller coaster ride for Shapely to be properly packaged for both Python 3.10 and Apple-silicon Macs, but now this is fully sorted out. That\u0026rsquo;s one less hassle when installing vpype.\n Removed deprecated API (#507)   With vpype 1.9, a number of APIs migrated from the vpype package to the vpype_cli package. The former APIs still worked but emitted deprecation warnings. They are now gone forever.\n","permalink":"https://bylr.info/articles/2022/07/06/annotated-release-notes-vpype-1.11/","summary":"This release further solidifies the block commands which were overhauled in vpype 1.9. It also introduces several changes revolving around the \u0026ldquo;plotting with paint\u0026rdquo; use-case, which typically requires the brush to be regularly dipped in a paint well. This can be achieved by inserting \u0026ldquo;dipping\u0026rdquo; patterns at regular intervals determined by the cumulative drawing distance. vpype 1.11 makes this process much easier.\nThanks a lot to Andee Collard for his useful feedback and providing this article\u0026rsquo;s banner!","title":"Annotated Release Notes: vpype 1.11"},{"content":"Following a recent discussion on Twitter, I decided to take yet another deep dive in my Python projects' documentation and fix once and for all the issues I had with it. I first focused on the automatically-generated API reference section and this article details the results of my finding. Specifically, I\u0026rsquo;m using vsketch\u0026rsquo;s API reference, which I recently updated, as an example (documentation source.\nThis article addresses the following objectives:\n Produce a beautiful API documentation based on the code docstrings that is both nice to look at and easy to navigate. Support for a proper table of content navigation down to each class/module\u0026rsquo;s member. Nice looking summary tables listing modules' and classes' contents.  This article targets an audience of FOSS maintainers who are unhappy with the state of their project\u0026rsquo;s API documentation, and are frustrated with the process of improving it. A basic understanding of Sphinx as well as an existing documentation setup is assumed. This article basically contains everything I wish I was told when I first started on my API reference improvement journey. For the beginners, I\u0026rsquo;ll provide pointers to help setting up a basic Sphinx.\nNote that although this article is structured as a tutorial, it covers tips and techniques which are likely useful for other kinds of documentation customisation.\nBasic setup As stated above, the basic steps to setup a Sphinx-based documentation project are outside the scope of the present article. I suggest reviewing the following resources to get started:\n @Mariatta made a brilliant tutorial on how to kick-start a Sphinx documentation project. Thomas Cokelaer has a very nice reStructuredText cheat sheet. Simon Willison wrote another cheat sheet which covers \u0026ldquo;the subset of reStructuredText worth committing to memory\u0026rdquo;. Obviously, Sphinx\u0026rsquo;s documentation is an important resource. Although it is somewhat arid for the newcomer, I strongly suggest not giving up on it. I had multiple \u0026ldquo;oh there it is!\u0026rdquo; moments with it in the process of writing this article. Finally, Read the Docs is likely the best place to host your documentation. It\u0026rsquo;s very simple to setup and free for open source projects.  As for the theme, my preference goes for Pradyun Gedam\u0026rsquo;s Furo. I\u0026rsquo;m using it with the default configuration, so the only requirement is to enable it in your conf.py file:\nhtml_theme = \u0026#34;furo\u0026#34; Note that some of the CSS provided in this article may need adjustments should you opt for a different theme.\nAutoapi setup After trying both autodoc/autosummary and Sphinx AutoAPI, I opted to use the latter. Here are the main reasons behind this choice:\n Autosummary does not generate TOC entries for API elements such as classes/modules and their members. This is due to a long-standing Sphinx limitation. Autoapi works around this limitation (albeit imperfectly, as we\u0026rsquo;ll later note). Autosummary defaults to not generating anything and is in my experience frustrating to setup. In contrast, autoapi produces usable output out-of-the-box. Templates are easier to write thanks to the rich \u0026ldquo;mapper\u0026rdquo; objects AutoAPI provides after parsing your code (see the AutoAPI objects section below).  Note that there are two things called \u0026ldquo;autoapi\u0026rdquo; floating on the Internet: the Sphinx AutoAPI project (documentation) is the good one. The other one is unmaintained and barely documented. Make sure you don\u0026rsquo;t loose time dealing with the wrong one.\nBasics Setting up Sphinx AutoAPI is covered in their documentation. It boils down to the following steps.\n Install the sphinx-autoapi package: $ pip install sphinx-autoapi  Add AutoAPI it to the Sphinx extension list: extensions = [ ..., \u0026#39;autoapi.extension\u0026#39;, ]  List your package directories (or the directory containing them) and set basic options: autoapi_dirs = [\u0026#39;../mypackage\u0026#39;] autoapi_type = \u0026#34;python\u0026#34;  Add the generated documentation to your index.rst toctree: .. toctree:: :maxdepth: 3... autoapi/index   Setting up templates We will customise Sphinx AutoAPI\u0026rsquo;s default templates. The easiest is to copy Sphinx AutoAPI\u0026rsquo;s default templates in your project to serve as a starting point.\nFirst, run the following commands (adjusting for your Python version) from your documentation directory:\n$ mkdir _templates $ mkdir _template/autoapi $ cp $VIRTUAL_ENV/lib/python3.10/site-packages/autoapi/templates/index.rst _templates/autoapi/ $ cp -r $VIRTUAL_ENV/lib/python3.10/site-packages/autoapi/templates/python _templates/autoapi/ Then, tell Sphinx AutoAPI of its template directory in your conf.py file:\nautoapi_template_dir = \u0026#34;_templates/autoapi\u0026#34; A useful tip is to make a Git commit just after copying the built-in templates, such that you can track (and revert) your modifications. I\u0026rsquo;ve used this extensively while working on my templates.\nAt this point, I suggest spending some time to become acquainted with the built-in templates and how they are organised and implemented. If you haven\u0026rsquo;t used it before, it is also useful to review the Jinja2 templating language documentation.\nOther configuration options autoapi_options The autoapi_options controls various aspect of the generated documentation, including the type of class/module members that are listed. Its default value is sensible but I still felt like customising it:\nautoapi_options = [ \u0026#34;members\u0026#34;, \u0026#34;undoc-members\u0026#34;, \u0026#34;show-inheritance\u0026#34;, \u0026#34;show-module-summary\u0026#34;, \u0026#34;imported-members\u0026#34;, ] In particular, I want the summary at the top of the module\u0026rsquo;s documentation (show-module-summary), but we will heavily customise it. Check the documentation for a list of available options and their descriptions.\nautoapi_keep_files Another useful option is autoapi_keep_files. Sphinx-autoapi generates .rst pages for the documentation during the build process, but defaults to deleting them after completion. It\u0026rsquo;s often useful to keep them around for inspection and debugging purposes:\nautoapi_keep_files = True autodoc_typehints This is technically an autodoc setting, but Sphinx AutoAPI honours it. It controls if/where type hints are included in the documentation. The possible values are the following:\n \u0026quot;signature\u0026quot;: type hints are included in the function signature, which appears first in the member\u0026rsquo;s documentation \u0026quot;description\u0026quot;: type hints are included within the function description, when the arguments are listed \u0026quot;both\u0026quot;: type hints are included in both places \u0026quot;none\u0026quot;: type hints are not included  My preference goes for \u0026quot;signature\u0026quot;:\nautodoc_typehints = \u0026#34;signature\u0026#34; AutoAPI objects Understanding the Sphinx AutoAPI objects is key to customising templates. They are one of the major difference with respect to autodoc/autosummary.\nIn order to generate the API documentation, the autodoc loads your actual code and uses Python\u0026rsquo;s introspection capabilities to extract the required information from your module and class objects. In contrast, Sphinx AutoAPI parses your Python code and builds a collection of so-called \u0026ldquo;mapper\u0026rdquo; objects which describe your code and its structure. These objects are then passed on as context to the Jinja2 templating engine. Oddly, the documentation doesn\u0026rsquo;t provide a reference about them, but their implementation is easy to read.\nHere is a summary of some of the attributes that are useful when writing templates:\n obj.name Name of the mapped object, e.g. \u0026quot;MyClass\u0026quot; or \u0026quot;my_method\u0026quot;. obj.id Fully qualified name of the object, used for cross-referencing, e.g. \u0026quot;my_module.MyClass\u0026quot; or \u0026quot;my_module.MyClass.my_method\u0026quot;. obj.summary Summary of the object\u0026rsquo;s docstring (i.e. the first line). obj.docstring Full docstring of the object. obj.display Indicates whether or not this object should be displayed, based on the options set in conf.py and the result of the autoapi-skip-member event (discussed later). obj.children (Modules and classes only) List children functions, methods, attributes, etc. obj.properties (Functions and methods only) List of properties, such as \u0026quot;classmethod\u0026quot;, \u0026quot;staticmethod\u0026quot;\u0026quot;, \u0026quot;abstractmethod\u0026quot;, \u0026quot;property\u0026quot;, etc. obj.obj.args (Functions and methods only) List of 4-tuples describing the function\u0026rsquo;s arguments. The first item is the star operator if any (\u0026quot;*\u0026quot;, \u0026quot;**\u0026quot;, or None), the second is the argument name, the third is the argument type or None, and the fourth is the argument default value or None. This key piece of data will enable us to recreate the signatures according to our needs.  When working on your documentation, it is often useful to inspect the contents of these mapper objects using a debugger. This can be achieved by adding an handler for the autoapi-skip-member event and setting a conditional breakpoint:\ndef skip_member(app, what, name, obj, skip, options): # conditional breakpoint here return skip def setup(sphinx): sphinx.connect(\u0026#34;autoapi-skip-member\u0026#34;, skip_member) This event will be triggered for every single Python object parsed from your code. By breaking, for example, when obj.name == \u0026quot;my_module\u0026quot;, the obj argument and its children can be fully inspected. I use the following run configuration in my IDE for this:\n Execute module: sphinx.cmd.build Parameters: -M html . _build Working directory: docs/  An autosummary-like macro By default, Sphinx AutoAPI provides a summary list of classes, functions, and attributes at the top of a module\u0026rsquo;s documentation, which is very nice. Our objective is to add a similar table at the top of each class description, to facilitate navigation. However, Sphinx AutoAPI uses its own autoapisummary directive, which derives from autosummary\u0026rsquo;s autosummary directive. Both suffer from the following limitations:\n The way callables are rendered is hard-coded and cannot be customised via templates. In particular, if autodoc_typehints is set to \u0026quot;signature\u0026quot; or \u0026quot;both\u0026quot;, autosummary will include type hints in the summary table as well. Unfortunately, this dramatically increases the length of the signature, which is detrimental to the table layout and usability. Alternatively, signatures can be entirely removed by using the :nosignatures: option. However, in this case, not even parenthesis are displayed, which hides the callable nature of the function. The best compromise is to have the full signature with their arguments, but without typing annotations. Properties are listed as functions, including their signature. This hides the fact that, API-wise, they behave as data members (though it would still be useful to indicate that they are in fact properties). There is not indication that a method is abstract, static, or class-based.  To address these shortcomings, we will create a Jinja2 template macro to replicate and improve on autosummary/autoapisummary functionality.1\nOur aim is to create tables where callable have their full – but unannotated – signature, where properties are indicated as such but rendered as attributes, and where static, class, and abstract methods are marked as such. Here is an example of this:\nBasic macro setup The basic insight is that a summary table can be implemented using Sphinx\u0026rsquo;s list-table:\n.. list-table:: Title :header-rows: 0 :widths: auto * - Item 1 - This is the description of the first item. * - Name 2 - This is also a description, but this time for the second item. * - ... - ...Such a table can be generated with the following Jinja macro:\n{% macro auto_summary(objs, title=\u0026#39;\u0026#39;) -%} .. list-table:: {{ title }} :header-rows: 0 :widths: auto {% for obj in objs %} * - obj.name - obj.summary {% endfor %} {% endmacro %} To test this, create a file named _templates/autoapi/macros.rst and add the code above. Then, make the following edits to the _templates/autoapi/python/module.rst file:\n At the top of the file, import macros.rst to make it available for use: {% import \u0026#39;macros.rst\u0026#39; as macros %}  Locate where the class summary is generated: .. autoapisummary:: {% for klass in visible_classes %} {{ klass.id }} {% endfor %}  Replace the code above by a call to our macro: {{ macros.auto_summary(visible_classes, title=\u0026#34;Classes\u0026#34;) }}   Here is the result I obtain with my project:\nThis is a good start, but we\u0026rsquo;re obviously far from the result we want. To start with, no cross-reference links are generated. And, had we passed functions or methods instead of classes to our macro, no signature would have been generated.\nCustom labels Before fixing our macro, we must discuss these nice looking \u0026ldquo;prop\u0026rdquo;, \u0026ldquo;static\u0026rdquo;, and \u0026ldquo;class\u0026rdquo; tag-like labels in the example tables above. These are implemented using a custom role with some CSS attached to it.\nThis StackOverflow answer explains how to create a custom role and make it globally available to your documentation. Basically, just add the following to your conf.py file:\nrst_prolog = \u0026#34;\u0026#34;\u0026#34; .. role:: summarylabel \u0026#34;\u0026#34;\u0026#34; The role directive creates a new role which can then be used as follows:\n:summarylabel:`My Label`Sphinx generates the corresponding HTML code:\n\u0026lt;span class=\u0026#34;summarylabel\u0026#34;\u0026gt;My label\u0026lt;/span\u0026gt; Since it sets an HTML class named after the role, it\u0026rsquo;s easy to adjust the label appearance using some custom CSS. Create a file named _static/css/custom.css in your documentation directory and add the following CSS:\nspan.summarylabel { background-color: var(--color-foreground-secondary); color: var(--color-background-secondary); font-size: 70%; padding-left: 2px; padding-right: 2px; border-radius: 3px; vertical-align: 15%; padding-bottom: 2px; filter: opacity(40%); } Note the use of CSS variables in order to support Furo\u0026rsquo;s dynamic night mode feature.\nFinally, we must tell Sphinx about this CSS file in the conf.py file:\nhtml_css_files = [ \u0026#34;css/custom.css\u0026#34;, ] Customising the table appearance A similar CSS approach can be used to customise the appearance of the summary table itself. By adding the :class: option to the list-table directive, we can tell Sphinx to attach an HTML class to the \u0026lt;table\u0026gt; element, which we can then customise with CSS:\n.. list-table:: Title :header-rows: 0 :widths: auto :class: summarytable * - ... - ...For my project, the only change I made to the default appearance is to force the table to span the entire width regardless of its contents. This can be done by adding the following code to our custom.css file:\ntable.summarytable { width: 100%; } Putting it all together We are now ready to put everything together and improve our auto_summary() macro to our liking. Here is the final code for macros.rst:\n{% macro _render_item_name(obj, sig=False) -%} :py:obj:`{{ obj.name }} \u0026lt;{{ obj.id }}\u0026gt;` {%- if sig -%} \\ ( {%- for arg in obj.obj.args -%} {%- if arg[0] %}{{ arg[0]|replace(\u0026#39;*\u0026#39;, \u0026#39;\\*\u0026#39;) }}{% endif -%}{{ arg[1] -}} {%- if not loop.last %}, {% endif -%} {%- endfor -%} ){%- endif -%} {%- endmacro %} {% macro _item(obj, sig=False, label=\u0026#39;\u0026#39;) %} * - {{ _render_item_name(obj, sig) }} - {% if label %}:summarylabel:`{{ label }}` {% endif %}{% if obj.summary %}{{ obj.summary }}{% else %}\\-{% endif +%} {% endmacro %} {% macro auto_summary(objs, title=\u0026#39;\u0026#39;) -%} .. list-table:: {{ title }} :header-rows: 0 :widths: auto :class: summarytable {% for obj in objs -%} {%- set sig = (obj.type in [\u0026#39;method\u0026#39;, \u0026#39;function\u0026#39;] and not \u0026#39;property\u0026#39; in obj.properties) -%} {%- if \u0026#39;property\u0026#39; in obj.properties -%} {%- set label = \u0026#39;prop\u0026#39; -%} {%- elif \u0026#39;classmethod\u0026#39; in obj.properties -%} {%- set label = \u0026#39;class\u0026#39; -%} {%- elif \u0026#39;abstractmethod\u0026#39; in obj.properties -%} {%- set label = \u0026#39;abc\u0026#39; -%} {%- elif \u0026#39;staticmethod\u0026#39; in obj.properties -%} {%- set label = \u0026#39;static\u0026#39; -%} {%- else -%} {%- set label = \u0026#39;\u0026#39; -%} {%- endif -%} {{- _item(obj, sig=sig, label=label) -}} {%- endfor -%} {% endmacro %} The work is now split in three macros:\n auto_summary() This is the \u0026ldquo;public\u0026rdquo; macro. It generates a table based on a list of mapper objects, with an optional title. It iterates over the list of objects, and, for each of them, determines if the signature should be generated (functions and non-property methods) and if some label should be attached. It then uses _item() to generate each object\u0026rsquo;s code. _item() This helper macro generates the code for each object, prepending a label to the summary if requested. _render_item_name() This helper macro focuses on generating the properly-cross-referenced object name. If the signature is requested, it iterates over the obj.obj.args list to produce a full (but unannotated) list of arguments.  Improving the default templates With our auto_summary() macro completed, we are now ready to customise our templates, but we still have one issue to resolve before we do so.\nCategorising objects with a custom Jinja2 test As we saw in the AutoAPI objects section, mapper objects representing modules or classes have a children attribute which lists the objects it contains. For example, a module\u0026rsquo;s children attribute lists all the classes, functions and attributes defined within it.\nIn order to categorise these children into separate sub-lists, the built-in templates heavily use the selectattr() and rejectattr() filters. For example, a list of classes in a module can be obtained as follows:\n{% set visible_children = module_object.children|selectattr(\u0026#34;display\u0026#34;)|rejectattr(\u0026#34;imported\u0026#34;)|list %} {% set visible_classes = visible_children|selectattr(\u0026#34;type\u0026#34;, \u0026#34;equalto\u0026#34;, \u0026#34;class\u0026#34;)|list %} This code selects the visible (but not imported) children from module_object, and then further selects children which have their type set to \u0026quot;class\u0026quot;. In the code above, \u0026quot;equalto\u0026quot; is known as a Jinja test. There are many such built-in tests in Jinja2.\nAs stated before, we aim to categorise properties as attributes instead of methods. To that end, we will have to filter methods whose properties attribute contains \u0026quot;property\u0026quot;. Intuition dictates that the following code achieves this:\n{% set property_methods = all_methods|selectattr(\u0026#34;properties\u0026#34;, \u0026#34;contains\u0026#34;, \u0026#34;property\u0026#34;)|list %} The bad news is that no such \u0026quot;contains\u0026quot; test exists by default in Jinja2. The good news is that it is trivial to add one.\nFirst, the actual test must be written. Add the following code to your conf.py file:\ndef contains(seq, item): return item in seq Then, we just need to add this test to the Jinja environment. Sphinx AutoAPI provides a hook for that:\ndef prepare_jinja_env(jinja_env) -\u0026gt; None: jinja_env.tests[\u0026#34;contains\u0026#34;] = contains autoapi_prepare_jinja_env = prepare_jinja_env With this in your conf.py file, the template code above will work as expected.\nUpdating templates We previously replaced one of module.rst\u0026rsquo;s use of autoapisummary by our auto_summary() macro (see Basic macro setup). It is now time to generalise the use of our macro. At this stage, the details of how this is done is to a large extent up to reader\u0026rsquo;s taste. The templates of vsketch can serve as fully-functional example and can readily be used in another projects.\nFor the module.rst template, I have opted to simplify the overview\u0026rsquo;s structure by just generating tables (without headings) for classes, functions, and attributes:\n{% if \u0026#34;show-module-summary\u0026#34; in autoapi_options and (visible_classes or visible_functions) %} {% block classes scoped %} {% if visible_classes %} {{ macros.auto_summary(visible_classes, title=\u0026#34;Classes\u0026#34;) }} {% endif %} {% endblock %} {% block functions scoped %} {% if visible_functions %} {{ macros.auto_summary(visible_functions, title=\u0026#34;Functions\u0026#34;) }} {% endif %} {% endblock %} {% block attributes scoped %} {% if visible_attributes %} {{ macros.auto_summary(visible_attributes, title=\u0026#34;Attributes\u0026#34;) }} {% endif %} {% endblock %} {% endif %} For the class.rst template, I chose to rework the structure of the documentation into two rubrics:\n{% if visible_methods or visible_attributes %} .. rubric:: Overview {% set summary_methods = visible_methods|rejectattr(\u0026#34;properties\u0026#34;, \u0026#34;contains\u0026#34;, \u0026#34;property\u0026#34;)|list %} {% set summary_attributes = visible_attributes + visible_methods|selectattr(\u0026#34;properties\u0026#34;, \u0026#34;contains\u0026#34;, \u0026#34;property\u0026#34;)|list %} {% if summary_attributes %} {{ macros.auto_summary(summary_attributes, title=\u0026#34;Attributes\u0026#34;)|indent(3) }} {% endif %} {% if summary_methods %} {{ macros.auto_summary(summary_methods, title=\u0026#34;Methods\u0026#34;)|indent(3) }} {% endif %} .. rubric:: Members {% for attribute in visible_attributes %} {{ attribute.render()|indent(3) }} {% endfor %} {% for method in visible_methods %} {{ method.render()|indent(3) }} {% endfor %} {% endif %} Note the use of the custom \u0026quot;contains\u0026quot; Jinja2 test we implemented earlier.\nHiding submodules Sphinx AutoAPI include all subpackages and submodules recursively, unless those are marked as private by prefixing their name with an underscore. In my packages' __init__.py file, I carefully import from submodules the objects which are meant to be public, but haven\u0026rsquo;t necessarily marked the submodules as private. Sphinx AutoAPI has no option to control whether or not to add them (I suggested adding one), so I had to filter them out manually. This is done with the autoapi-skip-member event handler we mentioned earlier:\ndef skip_member(app, what, name, obj, skip, options): # skip submodules if what == \u0026#34;module\u0026#34;: skip = True return skip def setup(sphinx): sphinx.connect(\u0026#34;autoapi-skip-member\u0026#34;, skip_member) Hiding members Likewise, it may happen that you want to hide specific members from the documentation without marking them as private. Again, the autoapi-skip-member event handler can do that. The following example is based from actual code in vsketch:\ndef skip_member(app, what, name, obj, skip, options): if \u0026#34;vsketch.SketchClass\u0026#34; in name: if obj.name in [ \u0026#34;vsk\u0026#34;, \u0026#34;param_set\u0026#34;, \u0026#34;execute_draw\u0026#34;, \u0026#34;ensure_finalized\u0026#34;, \u0026#34;execute\u0026#34;, \u0026#34;get_params\u0026#34;, \u0026#34;set_param_set\u0026#34;, ]: skip = True return skip Note that name is the fully qualified name of the object, so the vsk member has name set to vsketch.SketchClass.vsk. In contrast, obj.name is just the base name.\nAlso, for this to work as expected for modules, I had to change the following line in module.rst\n{% set visible_children = obj.children|selectattr(\u0026#34;short_name\u0026#34;, \u0026#34;in\u0026#34;, obj.all)|list %} into\n{% set visible_children = obj.children|selectattr(\u0026#34;display\u0026#34;)|selectattr(\u0026#34;short_name\u0026#34;, \u0026#34;in\u0026#34;, obj.all)|list %} Without this modification, objects marked as skipped would show up in the summary tables.\nOrdering By default, Sphinx AutoAPI generates the documentation in the same order as the code. This can be changed to alphabetical order, I like being in control from the code.\nIn vsketch, the top level content is determined by the imports in my package\u0026rsquo;s __init__.py file, so the import statements themself matter. Since I\u0026rsquo;m using isort, I had to short-circuit it in this particular case:\n# vsketch/__init__.py # isort: skip_file # Ordered for the documentation from .vsketch import Vsketch from .shape import Shape from .sketch_class import SketchClass, Param, ParamType from .easing import EASING_FUNCTIONS from .utils import working_directory Conclusion Well, this ended up being much longer than anticipated 😅 – if you made it this far, congratulations! 🎉\nHere is what we covered:\n We built on a basic Sphinx project and added AutoAPI to generate an API reference documentation. We created custom templates based on the built-in templates provided by AutoAPI. We reviewed the mapper objects created by AutoAPI to described our code. We learned how to use a debugger to easily inspect these objects. We crafted an autosummary-like macro named auto_summary() to build beautiful summary tables. We customised these tables with custom CSS. We used a custom Sphinx role and CSS to create tag-like labels to be used in the summary tables. We learned of Jinja2\u0026rsquo;s tests and created a custom one. We controlled the visibility of submodules and members using a autoapi-skip-member event handler. We learned how to control ordering from our code.  Like any software project, improving the documentation is a never-ending endeavour. As it turns out, there is one remaining issue that has been bugging me and is yet unresolved. Due to a limitation in Sphinx, AutoAPI has a tendency to mangle the TOC ordering, especially when section headings are emitted from the templates. Check these two issues for more information. Hopefully they\u0026rsquo;ll get solved in the future.\nI shall conclude by stating that, by all means, I do not consider myself a Sphinx expert — much to the contrary. I did spend a lot of time improving my API documentation, and figured it would be wasteful not to share my findings, especially given the relative scarcity of information on advanced Sphinx usage patterns. As a result, it is rather likely that I made mistakes and sub-optimal choices. If so, please do provide feedback, and I\u0026rsquo;ll update this article to improve it.\nEdit: updated title and intro to clarify the nature of the API discussed, i.e. Python API (2022-05-11).\n  Ideally, these shortcomings would be addressed using an extension and a custom directive, or even by contributing the improvement back to the Sphinx or AutoAPI projects. This is sadly beyond my skills. Also, the template method is anyway useful for highly specific requirements where writing an extension wouldn\u0026rsquo;t be warranted.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://bylr.info/articles/2022/05/10/api-doc-with-sphinx-autoapi/","summary":"Following a recent discussion on Twitter, I decided to take yet another deep dive in my Python projects' documentation and fix once and for all the issues I had with it. I first focused on the automatically-generated API reference section and this article details the results of my finding. Specifically, I\u0026rsquo;m using vsketch\u0026rsquo;s API reference, which I recently updated, as an example (documentation source.\nThis article addresses the following objectives:","title":"Generating beautiful Python API documentation with Sphinx AutoAPI"},{"content":"Hatch fills or pixel art plotting requires a rather precise estimate of your particular pen/paper combo\u0026rsquo;s stroke width.\nFor example, this test pixel art plot would benefit from a slightly thinner pitch to avoid the visible overlap between neighbouring lines:\nThere is no way around experience to find the optimal pitch. I\u0026rsquo;ve created the fill_test sketch to create custom charts with test patterns precisely tuned to the pen of interest. There is indeed no point to testing a rotring isograph .35mm pen with a generic 0.1mm to 1.0mm chart.\nHere is how the UI looks:\nBeyond the general layout options (page size, grid size, etc.), the Smallest Width and Width Increment parameters enable a fine-grained exploration of pitches around the nominal pen size.\nHere is an example with a rotring isograph .35mm in my notebook, which has a slight propensity for ink soaking. For this combo, fills with .4mm pitch yield the best results:\nTo use the sketch, download or clone my sketches repository and execute the sketch using your existing vsketch installation:\n$ vsk run path/to/sketchs/fill_test ","permalink":"https://bylr.info/articles/2022/04/28/sketch-fill-test/","summary":"Hatch fills or pixel art plotting requires a rather precise estimate of your particular pen/paper combo\u0026rsquo;s stroke width.\nFor example, this test pixel art plot would benefit from a slightly thinner pitch to avoid the visible overlap between neighbouring lines:\nThere is no way around experience to find the optimal pitch. I\u0026rsquo;ve created the fill_test sketch to create custom charts with test patterns precisely tuned to the pen of interest. There is indeed no point to testing a rotring isograph .","title":"Sketch: fill test pattern generator"},{"content":"The problem Several generative art algorithms, such as Truchet tiles, use a regular grid of square cells. For example, check this interactive demo from the Generative Design book or these few pieces of mine.\nNow, let\u0026rsquo;s say you want to generate an iteration of your algorithm for printing or plotting such that all margins around the grid are the same for the given paper size. You can of course adjust the number of cell rows and columns, but how should you size the cell such as to achieve uniform margins?\nThe image above illustrates the problem. For a given page of size $W \\times H$ and a regular grid of $N \\times M$ cells, what should be the cell size $s$ to achieve uniform margins $m$ around the grid? What is then the value of $m$?\nThe solution This is easy to solve with a bit of math. Here is the system of two equations that must be solved:\n \\[\\begin{cases} 2 \\cdot m \u0026#43; N \\cdot s = W \\\\ 2 \\cdot m \u0026#43; M \\cdot s = H \\end{cases}\\]  with all parameters ($N$, $M$, $W$, $H$) and the cell size $s$ being strictly positive.\nSolving this for $m$ and $s$ is no rocket science but Wolfram Alpha can do the job for you if your high school math is rusty!\nWe have the following solutions:\n \\[\\begin{cases} \\displaystyle s = \\frac{H - 2 m}{N}, \\quad m \u0026lt; \\frac{H}{2} \u0026amp; \\footnotesize M = N, \\; W = H \\\\ \\\\ \\displaystyle s = \\frac{H-W}{M-N}, \\quad m = \\frac{M W - H N}{2(M - N)} \u0026amp; \\footnotesize N\u0026lt;M, \\; W\u0026lt;H \\quad \\textrm{or} \\quad N\u0026gt;M, \\; W\u0026gt;H \\end{cases}\\]  The first solution corresponds to the special case of a square page size. In this case, the grid must be square ($N=M$) and the margins may have an arbitrary value, with the cell size varying accordingly. This is not very surprising.\nThe second solution is where things become interesting. As intuition dictates, it is valid only if the grid orientation (portrait or landscape) matches the paper orientation. If so, uniform margins is achieved by choosing a cell size of $s = \\frac{H-W}{M-N}$.\nNote that the resulting margin $m$ may, depending on the parameters, be negative. In this case, the grid overflows all around the page by a constant distance. This making plotting/printing your piece inconvenient, you will have to adjust $N$ and/or $M$ to reach a positive margin value.\nThe demo I made a demonstration sketch made with vsketch. Here is how it looks:\n   This is a simplified version of the code which can be used as a starting point for your next grid-based design:\nimport itertools import vsketch class MySketch(vsketch.SketchClass): N = vsketch.Param(5, 1) M = vsketch.Param(7, 1) def draw(self, vsk: vsketch.Vsketch) -\u0026gt; None: vsk.size(\u0026#34;a4\u0026#34;, landscape=False, center=False) # disable auto-centering cell_size = (vsk.height - vsk.width) / (self.M - self.N) margin = (self.M * vsk.width - self.N * vsk.height) / 2 / (self.M - self.N) if cell_size \u0026gt; 0: # account for the computed margin vsk.translate(margin, margin) # draw the grid for i, j in itertools.product(range(self.N + 1), range(self.M + 1)): vsk.point(i * cell_size, j * cell_size) else: # ERROR: N and M values must be adjusted! pass ","permalink":"https://bylr.info/articles/2022/04/13/grid-layout/","summary":"The problem Several generative art algorithms, such as Truchet tiles, use a regular grid of square cells. For example, check this interactive demo from the Generative Design book or these few pieces of mine.\nNow, let\u0026rsquo;s say you want to generate an iteration of your algorithm for printing or plotting such that all margins around the grid are the same for the given paper size. You can of course adjust the number of cell rows and columns, but how should you size the cell such as to achieve uniform margins?","title":"How to scale a grid on a page for uniform margins?"},{"content":"I originally intended vpype 1.10 to be a \u0026lsquo;quick-and-dirty\u0026rsquo;, bug-fix-only release but it ended up being quite substantial, so let\u0026rsquo;s dive in.\nNew features and improvements   Improved support for layer pen width and opacity in the viewer (#448)\n The \u0026ldquo;Pen Width\u0026rdquo; and \u0026ldquo;Pen Opacity\u0026rdquo; menus are now named \u0026ldquo;Default Pen Width\u0026rdquo; and \u0026ldquo;Default Pen Opacity\u0026rdquo;. The layer opacity is now used for display by default. It can be overridden by the default pen opacity by checking the \u0026ldquo;Override\u0026rdquo; item from the \u0026ldquo;Default Pen Opacity\u0026rdquo; menu. The layer pen width is now used for display by default as well. Likewise, it can be overridden by checking the \u0026ldquo;Override\u0026rdquo; item from the \u0026ldquo;Default Pen Width\u0026rdquo; menu.     This alone is reason to upgrade, and, if we\u0026rsquo;re being honest, it should have been done in the previous release. The display logic of the viewer is now as follows:\n By default, honor the layer\u0026rsquo;s pen width and opacity if present. If pen width and/or opacity is not set, revert to the value set in the menu (0.3mm / 80% by default). Either or both of the displayed pen width and opacity can be forced to the value in the menu using the new \u0026ldquo;Override\u0026rdquo; menu item.  It is worth noting that opacity is not a standalone layer property, but is part of its RGBA color property (vp_color). Weirdly, vpype 1.9\u0026rsquo;s viewer would honor the base color (RGB), but not its alpha chanel. (See next feature, though.)\nBy the way, this article\u0026rsquo;s cover image is a screenshot of the viewer made with this command:\n(Yes, this is a properly syntax-highlighted vpype command made with a custom script and Rich\u0026rsquo;s new SVG export. This is very preliminary, but, in time, something to improve on and deploy more widely in the doc and elsewhere.)\n Added the alpha command to set layer opacity without changing the base color (#447, #451)   While working on the viewer improvements, I realized how inconvenient it was to set an arbitrary opacity value. Using CSS color names (e.g. color red) always sets opacity to 100% and there is no way around the hex notation for a custom value (e.g. color #ff00007f or color #f007). The new alpha command fills that gap: color red alpha 0.5.\n Added HPGL configuration for the Calcomp Artisan plotter (thanks to Andee Collard and @ithinkido) (#418)   Good news for Calcomp Artisan\u0026rsquo;s owners! Let this be a reminder that I welcome this kind of contribution. Though I\u0026rsquo;d like to, I can\u0026rsquo;t own every single type of vintage plotter! 😅\n  The read command now better handles SVGs with missing width or height attributes (#446)\nWhen the width or height attribute is missing or expressed as percent, the read command now attempts to use the viewBox attribute to set the page size, defaulting to 1000x1000px if missing. This behavior can be overridden with the --display-size and the --display-landscape parameters.\n   I recently came across a SVG with a viewBox defined but no width/height attributes:\n\u0026lt;svg xmlns=\u0026#34;http://www.w3.org/2000/svg\u0026#34; viewBox=\u0026#34;0 0 1191.26 1684.49\u0026#34;\u0026gt;...\u0026lt;/svg\u0026gt; In such an instance, using the read command used to default to an A4 page size, while the vpype.read_svg() API (and friends) would default to a 1000x1000px page size. This is both inconsistent and missing the opportunity to fallback on the viewBox. vpype now fully delegates this fallback logic to svgelements, which does a good job at making the most of the available information. Also, if everything is missing (or width/height are expressed in percents), vpype consistently falls back to 1000x1000px.\n Added the --dont-set-date option to the write command (#442)   This one is a bit niche. vpype adds some metadata to the SVG, including the date and time at which it was generated (note the \u0026lt;dc:date\u0026gt; tag):\n$ vpype line 1cm 1cm 5cm 3cm layout a6 write -f svg - \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34; ?\u0026gt; \u0026lt;svg xmlns=\u0026#34;http://www.w3.org/2000/svg\u0026#34; xmlns:cc=\u0026#34;http://creativecommons.org/ns\u0026#34; xmlns:dc=\u0026#34;http://purl.org/dc/elements/1.1/\u0026#34; xmlns:ev=\u0026#34;http://www.w3.org/2001/xml-events\u0026#34; xmlns:inkscape=\u0026#34;http://www.inkscape.org/namespaces/inkscape\u0026#34; xmlns:rdf=\u0026#34;http://www.w3.org/1999/02/22-rdf-syntax-ns\u0026#34; xmlns:sodipodi=\u0026#34;http://sodipodi.sourceforge.net/DTD/sodipodi-0.dtd\u0026#34; xmlns:xlink=\u0026#34;http://www.w3.org/1999/xlink\u0026#34; baseProfile=\u0026#34;tiny\u0026#34; height=\u0026#34;14.8cm\u0026#34; version=\u0026#34;1.2\u0026#34; viewBox=\u0026#34;0 0 396.85039370078744 559.3700787401575\u0026#34; width=\u0026#34;10.5cm\u0026#34;\u0026gt; \u0026lt;metadata\u0026gt; \u0026lt;rdf:RDF\u0026gt; \u0026lt;cc:Work\u0026gt; \u0026lt;dc:format\u0026gt;image/svg+xml\u0026lt;/dc:format\u0026gt; \u0026lt;dc:source\u0026gt;vpype line 1cm 1cm 5cm 3cm layout a6 write -f svg - \u0026lt;/dc:source\u0026gt; \u0026lt;dc:date\u0026gt;2022-04-07T10:15:00.532842\u0026lt;/dc:date\u0026gt; \u0026lt;/cc:Work\u0026gt; \u0026lt;/rdf:RDF\u0026gt; \u0026lt;/metadata\u0026gt; \u0026lt;defs/\u0026gt; \u0026lt;g fill=\u0026#34;none\u0026#34; id=\u0026#34;layer1\u0026#34; inkscape:groupmode=\u0026#34;layer\u0026#34; inkscape:label=\u0026#34;1\u0026#34; stroke=\u0026#34;#0000ff\u0026#34; style=\u0026#34;display:inline\u0026#34;\u0026gt; \u0026lt;line x1=\u0026#34;122.8346\u0026#34; x2=\u0026#34;274.0157\u0026#34; y1=\u0026#34;241.8898\u0026#34; y2=\u0026#34;317.4803\u0026#34;/\u0026gt; \u0026lt;/g\u0026gt; \u0026lt;/svg\u0026gt; This is all well and good until you automate the generation of SVGs under a version control system, which is what I did for vpype-perspective\u0026rsquo;s documentation figures. A PyDoIt dodo.py files converts any .vpy file it finds into corresponding SVGs – basically a Python-powered, overcharged Makefile. (This is a rather neat process which, by the way, should get its own article someday.) In this kind of setup, having a ever-changing date in the SVG yields many unwanted VCS diffs which can now be avoided using this option.\nBug fixes  Fixed an issue with forlayer where the _n variable was improperly set (#443)   One word: inexcusable 🙄\n Fixed an issue with write where layer opacity was included in the stroke attribute instead of using stroke-opacity, which, although compliant, was not compatible with Inkscape (#429)   This one is Inkscape\u0026rsquo;s fault. Using stroke-opacity is \u0026ldquo;more compatible\u0026rdquo; anyways, so it\u0026rsquo;s a good move regardless.\n Fixed an issue with vpype --help where commands from plug-ins would not be listed (#444)   I ran into an issue with Click where a sub-command plug-in using APIs from the top-level command\u0026rsquo;s package (a scheme widely used by vpype and its plug-ins) would fail because of circular imports. The workaround I used in vpype 1.9 meant that plug-ins were no longer listed in vpype --help. This is fixed now, but this may not be the end of the story. I tried – and failed – to reproduce the original issue in a minimal demo project and I\u0026rsquo;ll have to further dig into this someday.\n Fixed a minor issue where plug-ins would be reloaded each time vpype_cli.execute() is called (#444)   By \u0026ldquo;minor\u0026rdquo;, I mean that this amounted to a tiny performance hit for Python scripts using vpype\u0026rsquo;s execute() API multiple times.\n Fixed a rendering inconsistency in the viewer where the ruler width could vary by one pixel depending on the OpenGL driver/GPU/OS combination (#448)   The ruler of vpype\u0026rsquo;s viewer is supposed to be 20px wide, but it turns out that either of the horizontal or the vertical one was 21px wide instead. Which one? It depends on the platform and my Intel/AMD- and M1-based laptops disagreed on the matter! 😲\nIt took me a while to discover that this is due to drawing lines at a 0.5px offset with respect to the pixel grid, leading to unpredictable rounding behavior. This is basically what happens when drawing horizontal or vertical lines with integer coordinates, and I wrote about it a few days ago.\nYou\u0026rsquo;d think that not one soul would care about this, but some of my tests are based on comparing newly rendered images of the viewer with previously-generated reference images, and those tests would fail on my new M1 Mac.\nAPI changes  Added vpype_cli.FloatType(), vpype_cli.IntRangeType(), vpype_cli.FloatRangeType(), and vpype_cli.ChoiceType() (#430, #447)   These Click types provide support for property and expression substitution. They were missing from vpype 1.9 because they aren\u0026rsquo;t needed internally. Plug-ins, however, wanted them, including flow imager and my new vpype-perspective.\n Changed vpype.Document.add_to_sources() to also modify the vp_source property (#431)   This will simplify the code needed to handle sources in plug-ins.\n Changed the parameter name of both vpype_viewer.Engine() and vpype_viewer.render_image() from pen_width and pen_opacity to default_pen_width and default_pen_opacity (breaking change) (#448) Added override_pen_width and override_pen_opacity boolean parameters to both vpype_viewer.Engine() and vpype_viewer.render_image() (#448) Added a set_date:bool = True argument to vpype.write_svg() (#442) Changed the default value of default_width and default_height arguments of vpype.read_svg() (and friends) to None to allow svgelement better handle missing width/height attributes (#446)   These are the API counterparts of some of the changes described before.\nOther changes  Added support for Python 3.10 and dropped support for Python 3.7 (#417)   Walruses have appeared already! 🦭\n Updated code base with modern typing syntax (using pyupgrade) (#427)   I was this year old when I learned that you can use modern typing syntax (such as list[int] | None) with older Python versions thanks to this statement:\nfrom __future__ import annotations I swiftly ran pyupgrade on the entire code base to bring it up to date.\n Updated the documentation template (#428)   It looks cleaner now IMO, though there is still a whole lot that could be improved.\n Updated installation instructions to use pipx (#428)   I have yet to get over how long it took me to realize this! 😳 I\u0026rsquo;m sorry for everyone who has struggled with virtual environments to install vpype!\n","permalink":"https://bylr.info/articles/2022/04/07/annotated-release-notes-vpype-1.10/","summary":"I originally intended vpype 1.10 to be a \u0026lsquo;quick-and-dirty\u0026rsquo;, bug-fix-only release but it ended up being quite substantial, so let\u0026rsquo;s dive in.\nNew features and improvements   Improved support for layer pen width and opacity in the viewer (#448)\n The \u0026ldquo;Pen Width\u0026rdquo; and \u0026ldquo;Pen Opacity\u0026rdquo; menus are now named \u0026ldquo;Default Pen Width\u0026rdquo; and \u0026ldquo;Default Pen Opacity\u0026rdquo;. The layer opacity is now used for display by default. It can be overridden by the default pen opacity by checking the \u0026ldquo;Override\u0026rdquo; item from the \u0026ldquo;Default Pen Opacity\u0026rdquo; menu.","title":"Annotated Release Notes: vpype 1.10"},{"content":"When I started using my new M1 Max MacBook Pro in December, a bunch of vpype\u0026rsquo;s tests started to fail. The failing tests were all image-based: an image is rendered and then compared to a previously-generated, reference image. This process is made easy thanks to this Pytest fixture.\nIn this case, the reference images were generated long ago on my previous, Intel/AMD-based MacBook Pro. This GIF highlights the discrepancy I\u0026rsquo;d get with images generated on my new computer (notice how the ruler\u0026rsquo;s thickness varies):\nAs I\u0026rsquo;m currently working on this viewer again, I finally spent two days tracking this issue – and finally found its cause.\nWithout giving it a thought, I first used integer coordinates for those ruler lines. However, coordinates refer to pixel boundaries – not pixel centres. This means than an horizontal line with integer coordinates (e.g. [(2, 2), (7, 2)]) sits halfway between two consecutive rows of pixel:\nWhich of the 2nd or 3rd row of pixel eventually gets drawn is up to a coin toss – or rather the rounding strategy of your particular OpenGL driver/GPU/OS combination.\nBy offsetting the coordinates by half a pixel (e.g. [(2, 2.5), (7, 2.5)]), one can force the line on a specific pixel row and avoid any rounding:\nThis makes the rendering more predictable across platforms.\nUltimately, the fix was very simple (I just changed the ruler thickness from 20 to 19.5), but figuring it out was tricky (relevant discussions on ModernGL\u0026rsquo;s Discord server). Hopefully I wont forget about it after writing this TIL.\n","permalink":"https://bylr.info/articles/2022/04/05/til-aligning-horizontal-or-vertical-lines-to-the-pixel-grid-with-opengl/","summary":"When I started using my new M1 Max MacBook Pro in December, a bunch of vpype\u0026rsquo;s tests started to fail. The failing tests were all image-based: an image is rendered and then compared to a previously-generated, reference image. This process is made easy thanks to this Pytest fixture.\nIn this case, the reference images were generated long ago on my previous, Intel/AMD-based MacBook Pro. This GIF highlights the discrepancy I\u0026rsquo;d get with images generated on my new computer (notice how the ruler\u0026rsquo;s thickness varies):","title":"TIL: aligning horizontal or vertical lines to the pixel grid with OpenGL"},{"content":"vpype \\ text -l1 -p 0 3.5cm \"Custom layer name/color/pen width\" \\ text -l2 -p 5cm 4.5cm -s 24 \"Properties\" \\ text -l2 -p 2cm 5.5cm -s 20 \"Expressions\" \\ text -l1 -p 6cm 6.5cm -s 24 \"Better/new block processors\" \\ text -l2 -p 3cm 8cm \"...and much more!\" \\ layout -m 0.3cm -l 10x3.5cm \\ penwidth -l2 0.5mm \\ color -l2 \"%Color(226,200,0)%\" \\ color -l1 \"%Color(3,118,207)%\" \\ color -l1 blue \\ show -- vpype 1.9 is finally out! 🎉\nI recently stumbled upon a post by Simon Willison where he promotes the idea of annotated release notes. As it turns out, this release is, by any metric I can think of, the biggest and most transformative so far. The associated change log is consequently rather unwieldy and calls, you guessed it 💡, for the present annotated release notes.\n(Note: although the original release notes are extensively quoted in this article, I reshuffled and shortened the original material. Make sure to check the base material for an authoritative list of change.)\nProperties Basics   Added support for global and per-layer properties (#359)\nThis feature introduces metadata to the pipeline in the form of properties which may either be attached to specific layers (layer property) or all of them (global property). Properties are identified by a name and may be of arbitrary type (e.g. integer, floating point, color, etc.). A number of system properties with a specific name (prefixed with vp_) and type are introduced to support some of the new features.\n   Metadata is data which says something about other data, and vpype lacked such a thing. Until now, what was passed from one command to the next consisted exclusively of paths sorted into layers, without any context such as what the color of these paths might be. One command could \u0026ldquo;know\u0026rdquo; about something (e.g. read knows, from the SVG, the color of a layer), but it could not \u0026ldquo;tell\u0026rdquo; the next command(s) about it.\nThis is no more, thanks to properties. They offer a generic mechanism to attach data to pipeline and layers. They are the backbone of several features introduced today, and lay the ground for future features within vpype or in plug-ins.\nLayer color, pen width, and name  Layer color, pen width, and name are now customizable (#359, #376, #389)  The read commands now sets layer color, pen width, and name based on the input SVG if possible. The new color, penwdith, and name commands can be used to modify layer color, pen width, and name. The new pens command can apply a predefined or custom scheme on multiple layers at once. Two common schemes are built-in: rgb and cmyk. Custom schemes can be defined in the configuration file. The show and write commands now take into account these layer properties.     Supporting arbitrary layer colors, pen widths, and names, has long been amongst the most requested features. Well, thanks to properties, here they are. It happens automagically when using read, and the new commands can further customise these values:\n$ vpype \\  rect --layer 1 0 0 5cm 5cm \\  color --layer 1 purple \\  penwidth --layer 1 0.5mm \\  circle --layer 2 4cm 4cm 2cm \\  color --layer 2 orange \\  penwidth --layer 2 5mm \\  show The new, high-level color, penwidth, and name commands are simple wrappers which change the value of specific system properties (i.e. vp_color, vp_pen_width, resp. vp_name):\n$ vpype random name \u0026#34;hello\u0026#34; color purple penwidth 0.1mm proplist --layer 1 listing 3 properties for layer 1 vp_color: (color) #800080 vp_name: (str) hello vp_pen_width: (float) 0.37795275590551186 System properties differ from \u0026ldquo;regular\u0026rdquo; properties only in the sense that they have special meaning to vpype. By convention, their name is prefixed with vp_.\nSpecial mention for the new pens command, which is short for here is the set of pens I intend to use for this plot. It sets in bulk layer colors, pen widths and/or names all at once, based on a built-in or custom configuration. For example, this produces a CMYK SVG using the flow imager plug-in:\n$ vpype \\  flow_img [...] --cmyk input.jpg \\  pens cmyk \\  write output.svg    Introduced new commands for low-level inspection and modification of properties (#359)\n propget: gets the value of a given global or layer property proplist: lists all global and/or layer properties and their value propset: sets the value of a given global or layer property propdel: deletes a given global or layer property propclear: removes all global and/or layer properties     These are low-level commands to interact with properties. Although they have limited use in real-world workflows, they come in handy when learning about properties or crafting complex pipelines.\n  Updated layer operation commands to handle properties (#359)\n When a single source layer is specified and --prob is not used, the lcopy and lmove commands now copy the source layer\u0026rsquo;s properties to the destination layer (possibly overwriting existing properties). When --prob is not used, the lswap command now swaps the layer properties as well. These behaviors can be disabled with the --no-prop option.     With properties, some of the layer manipulation commands became somewhat ambiguous. For example, what happens with properties when using lmove all 1 (merges all layers into layer one) or move --prob 0.5 1 2 (picks geometries from layer 1 with a 50% probability and moves them to layer 2)?\nI opted for a strategy where layer properties are affected only for unambiguous cases. This is basically when a single layer is moved/copied and when probabilistic behaviour is not used at all. In all other cases, the layer properties are left unchanged.\nFrom SVG attributes to properties   Added the --attr option to the read command to (optionally) sort geometries by attributes (e.g. stroke color, stroke width, etc.) instead of by SVG layer (#378, #389)\n  The read and write commands now preserve a sub-set of SVG attributes (experimental) (#359, #389)\nThe read command identifies SVG attributes (e.g. stroke-dasharray) which are common in all geometries within each layer. These attributes are saved as layer properties with their name prefixed with svg_ (e.g. svg_stroke-dasharray). The write command can optionally restore these attributes in the output SVG using the --restore-attribs option.\n   As noted, the read command now tries to extract SVG attributes and store them as layer properties. There are two motivations for that. First, it enables the write command to optionally restore these attributes in the output file, in order to achieve a higher degree of fidelity. (This feature is experimental and opt-in for the time being.) Second, it enables future features or plug-ins to do neat things such as generating hatch fills when fill is set to a color, or cutting paths in bits to emulate stroke-dasharray if defined.\nNow, since properties are only available at the layer level (or globally), read discards SVG attributes that are not shared amongst every paths within a given layer. Let\u0026rsquo;s take an example:\n\u0026lt;svg xmlns=\u0026#34;http://www.w3.org/2000/svg\u0026#34; width=\u0026#34;650\u0026#34; height=\u0026#34;650\u0026#34;\u0026gt; \u0026lt;circle cx=\u0026#34;150\u0026#34; cy=\u0026#34;150\u0026#34; r=\u0026#34;100\u0026#34; stroke=\u0026#34;red\u0026#34; stroke-width=\u0026#34;0.5mm\u0026#34; fill=\u0026#34;green\u0026#34; /\u0026gt; \u0026lt;rect x=\u0026#34;400\u0026#34; y=\u0026#34;200\u0026#34; width=\u0026#34;200\u0026#34; height=\u0026#34;400\u0026#34; stroke=\u0026#34;blue\u0026#34; stroke-width=\u0026#34;0.5mm\u0026#34; fill=\u0026#34;green\u0026#34; /\u0026gt; \u0026lt;path d=\u0026#34;M250,600 l-200,0 l0,-200 z\u0026#34; stroke=\u0026#34;blue\u0026#34; stroke-width=\u0026#34;0.1mm\u0026#34; fill=\u0026#34;green\u0026#34; /\u0026gt; \u0026lt;/svg\u0026gt; This SVG only contains top-level elements, which vpype loads in layer 1 by default. The fill property is common to all paths and thus stored as a layer property, but the stroke and stroke-width attributes are heterogeneous and thus discarded. As a result, the show command uses the default color and pen width.\n$ vpype read example.svg proplist --layer 1 show listing 1 properties for layer 1 svg_fill: (str) green To address this issue, the read command has now the option to create layers based on SVG attributes instead of structure:\n$ vpype read --attr stroke --attr stroke-width example.svg proplist --layer all show listing 5 properties for layer 1 svg_fill: (str) green svg_stroke: (str) red svg_stroke-width: (str) 0.5mm vp_color: (color) #ff0000 vp_pen_width: (float) 1.8897648 listing 5 properties for layer 2 svg_fill: (str) green svg_stroke: (str) blue svg_stroke-width: (str) 0.5mm vp_color: (color) #0000ff vp_pen_width: (float) 1.8897648 listing 5 properties for layer 3 svg_fill: (str) green svg_stroke: (str) blue svg_stroke-width: (str) 0.1mm vp_color: (color) #0000ff vp_pen_width: (float) 0.37795296000000006 In this case, read creates one layer per unique combination of stroke and stroke-width attribute, resulting in a total of three layers, each assigned with the correct properties, and correctly displayed by show.\nSource files  The read command now records the source SVG paths in the vp_source and vp_sources system properties (see the documentation) (#397, #406, #408)   The idea of the vp_source and vp_sources properties is to keep track of the files from which the content of the pipeline originates from. The vp_source property is a single path, which is overwritten by the last command importing from a file. The vp_sources property is a set of all source files encountered so far. Both properties are pathlib.Path instances.\nThis is, for example, what happens when using read twice:\n$ vpype read machine_typography_01_3.svg read machine_typography_02_3.svg proplist -g listing 5 global properties svg_fill: (str) black svg_stroke: (str) none vp_page_size: (tuple) (396.850608, 559.3703808000001) vp_source: (PosixPath) /private/tmp/MT/machine_typography_02_3.svg vp_sources: (set) {PosixPath(\u0026#39;/private/tmp/MT/machine_typography_01_3.svg\u0026#39;), PosixPath(\u0026#39;/private/tmp/MT/machine_typography_02_3.svg\u0026#39;)} Here, vp_source points to the file read by the last read command, but vp_sources contains all two source files.\nCurrently, read is the only command which sets these variables, but the idea is that any command involved with reading a file (SVG or otherwise) should set these properties, including plug-ins such as hatched, flow imager, or vpype-embroidery.\nOne of the most common use case is to name the output file after the input file:\n$ vpype flow_img [...] my_image.png write \u0026#34;{vp_name.stem}_converted.svg\u0026#34; Note the use of a property substitution pattern, which brings us to the next topic.\nProperty substitution   Added property substitution to CLI user input (#395)\nThe input provided to most commands' arguments and options may now contain substitution patterns which will be replaced by the corresponding property value. Property substitution patterns are marked with curly braces (e.g. {property_name}) and support the same formatting capabilities as the Python\u0026rsquo;s format() function.\n   This is where things start becoming \u0026ldquo;meta\u0026rdquo;! 🤯\nAs shown in the previous example, the value of a property may now be used anywhere as input using property substitution patterns.\nHere is another example where the full path of the input file is drawn and displayed:\n$ vpype read example.svg text -p 0.5cm 0.5cm \u0026#34;{vp_source}\u0026#34; show Again, vp_source is a pathlib.Path instance, so {vp_source.name} (file name) or {vp_source.stem} (file name without extension) could be used instead.\nMultiple substitution patterns can be combined and mixed with regular text. For example, this creates an output file in the same directory as, and named after, the input file:\n$ vpype read example.svg linesort \\  write \u0026#34;{vp_source.parent}/{vp_source.stem}_optimised.svg\u0026#34; Of course, when using vpype interactively, it\u0026rsquo;s easier to simply spell out the output file name. Instead, this kind of mechanism makes it considerably easier to write generic, reusable shell scripts.\nNote that, since property substitution internally relies on Python\u0026rsquo;s str.format() function, the number formatting mini-language is available as well (e.g. {vp_pen_width:.02f}). See the documentation for some examples.\nNow, taking a step back, this feature is neat indeed, but its usefulness turns out to be limited in many non-trivial, real-world scenarios. I had hoped it would unlock several workflows I had in mind, but it just did not - or not elegantly enough. So much so that I even considered dropping the feature altogether.\nThis was a bit frustrating, to say the least. And ultimately lead to what is the next big chapter of this release.\nExpressions   Added expression substitution to CLI user input (#397)\nThe input provided to most command\u0026rsquo;s arguments and options may now contain expression patterns which are evaluated before the command is executed. Expression patterns are marked with the percent symbol % (e.g. %3+4%) and support a large subset of the Python language. A lot of examples were added in the cookbook.\n   This is possibly the most transformative feature brought to vpype since its inception: anything between pairs of % characters is now evaluated as (a sub-set of) Python code, and the result is substituted in the input before it reaches the actual command. The documentation has been updated with a whole new section about expressions (which I\u0026rsquo;m not going to repeat here), and the cookbook has plenty of examples making use of them. Do check them out for a taste of what expressions are capable of!\nThis feature blurs the lines between a mere CLI tool and a programming language. This begs the question of why not using a programming language in the first place, a point raised by fellow Python dev and flow imager author Jonas Serych. vpype even offers a proper API for that!\nHere are my thoughts about this:\n Users of vpype are often not Python developers \u0026ndash; or developers at all. Expressions build on existing vpype knowledge and bring, at least through examples and recipes that can be copy/pasted/customized, tiny bits of programs which are readily useful, without the need to learn much of the Python syntax and ecosystem. For many real-world cases (see the examples linked in the release notes), the resulting one-liners are more compact than the equivalent in proper code - even Python, even with vpype API. (Arbitrarily complex pipelines can of course be conceivably crafted as counter-examples, but this is besides the point.)   Added the eval command as placeholder for executing expressions (#397)   Though expressions can be used in any command\u0026rsquo;s input, some \u0026ldquo;space\u0026rdquo; dedicated to them in the pipeline can be useful. Typical cases include variable initialization or querying the user for some parameter with the input() function. Several examples shown or linked below make use of this.\nBlock processors   Improved block processors (#395, #397)\n Simplified and improved the infrastructure underlying block processors for better extensibility. The begin marker is now optional and implied whenever a block processor command is encountered. Note: the end marker must always be used to mark the end of a block. Commands inside the block now have access to the current layer structure and its metadata.     Block processors hardly got any love since the first release of vpype and, as far as I can tell, weren\u0026rsquo;t used much - if at all - due to their limitations. Properties and expressions completely reverse this situation and block processors are now where the magic happens. The changes above lay the ground work for this.\n  Improved the grid block processor (#397)\n The page size is now updated according to the grid size. The command now sets expression variables for use in the nested pipeline. Cells are now first iterated along rows instead of columns.    The repeat block processor now sets expression variables for use in the nested pipeline (#397)\n  Added forfile block processor to iterate over a list of file (#397)\n  Added forlayer block processor to iterate over the existing layers (#397)\n  The read command now will ignore a missing file if --no-fail parameter is used (#397)\n  Changed the initial default target layer to 1 (#395)\nPreviously, the first generator command of the pipeline would default to create a new layer if the --layer option was not provided. This could lead to unexpected behaviour in several situation. The target layer is now layer 1. For subsequent generators, the existing behaviour of using the previous generator target layer as default remains.\n   That\u0026rsquo;s two new block processor commands, and another two finally coming to life, plus a few changes to make them work better with real-world workflows.\nOne of the key changes is that block processors now set temporary expression variables (prefixed with _) that can be used in the nested pipeline. They are listed in each command\u0026rsquo;s help text:\n$ vpype grid --help Usage: vpype grid [OPTIONS] NX NY Creates a NX by NY grid of geometry [...] The following variables are set by `grid` and available for expressions: _nx: number of columns (NX) _ny: number of rows (NY) _n: total number of cells (NX*NY) _x: current column (0 to NX-1) _y: current row (0 to NY-1) _i: current cell (0 to _n-1) [...] Another novelty is the introduction of two new block processor commands:\n The forfile command accepts a pathname pattern (e.g. *.svg) and executes the nested pipeline for each of the paths it expends into. It makes things like batch processing files, merging multiple SVGs into a multilayer file, or laying out multiple files on a grid a breeze. The forlayer command executes the nested pipeline for each of the exising layers, which is useful, e.g., to export one file per layer.  Checks the related documentation for more details.\nThis example, taken from the grid layout recipe, demonstrates best what vpype 1.9 is about:\n$ vpype \\  eval \u0026#34;files=glob(\u0026#39;*.svg\u0026#39;)\u0026#34; \\  eval \u0026#34;cols=6; rows=ceil(len(files)/cols)\u0026#34; \\  eval \u0026#34;names={};n=100\u0026#34; \\  grid -o 10cm 15cm \u0026#34;%cols%\u0026#34; \u0026#34;%rows%\u0026#34; \\  read --no-fail \u0026#34;%files[_i] if _i \u0026lt; len(files) else \u0026#39;\u0026#39;%\u0026#34; \\  layout -m 0.5cm 10x15cm \\  forlayer \\  eval \u0026#34;%if _name not in names: names[_name] = n; n = n+1%\u0026#34; \\  lmove %_lid% \u0026#34;%names[_name]%\u0026#34; \\  end \\  end \\  write combined.svg It creates a grid layout from multiple SVG files, combining layers using their name (e.g. all \u0026ldquo;yellow\u0026rdquo; layers in input files are merged in a single \u0026ldquo;yellow\u0026rdquo; layer in the output file). Check the recipe for a detailed explanation.\nThis pipeline has it all:\n extensive use of expressions, two nested blocks, using their expression variables (prefixed with _), use of properties (via the _name variable set by forlayer, which contains the current layer\u0026rsquo;s vp_name property).  Here is how it looks when run on my Machine Typography #ptpx project:\nOther changes Note: This is the last version of vpype to support Python 3.7.\n It\u0026rsquo;s the year of the walrus for vpype! 🦭\n Added pagerotate command, to rotate the page layout (including geometries) by 90 degrees (#404)   This command is useful for plotters without native support for both portrait and landscape orientations. Your plotter support only, say, landscape orientation and you want to plot a portrait-oriented file? This pipeline does the trick:\n$ vpype read portrait_input.svg pagerotate wrote landscape_output.svg   Added --keep option to the ldelete command (to delete all layers but those specified) (#383)   There was formerly no way to delete all layers but one. The new --keep option fills this gap.\n Pinned poetry-core to 1.0.8 to enable editable installs (#410)   Poetry finally supports editable installs thanks to PEP 660 🎉\nThis change is relevant when developing jointly on vpype and another project that depends on it (e.g. vsketch, or some plug-in). In such cases, vpype can now be installed in editable mode from a local checkout. Modifications made to it will immediately be available to the dependent project:\n$ cd my-plugin $ source venv/bin/activate $ git clone https://github.com/abey79/vpype ../vpype $ pip install -e ../vpype   Fixed an issue with the random command when using non-square area (#395)   That\u0026rsquo;s a two-year-old bug I can\u0026rsquo;t believe I hadn\u0026rsquo;t seen before 🙄 (I use random a lot when testing out stuff during development.)\n Renamed the bundled config file to vpype_config.toml (#359)   This is the config file bundled with vpype. It used to be called hpgl_devices.toml, but now it also contains the build-in configurations of the new pens command (cmyk and rgb). The old name didn\u0026rsquo;t make sense anymore.\nAPI changes:\n Moved all CLI-related APIs from vpype to vpype_cli (#388) Updated the block processor API (breaking change) (#395) \u0026hellip;   This release comes with scores of changes at the API level (to many to list here). Two of these changes deserve a note though.\nFirst, a fair amount of infrastructure used by the vpype CLI (e.g. the @generator decorator and friends) used to reside in the vpype package instead of vpype_cli. This is not ideal for many reasons and I\u0026rsquo;m moving away from it. vpype should be a \u0026ldquo;pure\u0026rdquo; library, whereas vpype_cli should contain everything needed for its CLI (and for plug-ins). These are not yet breaking changes but will generate deprecation warnings with most plug-ins. I will ensure that they are fixed ASAP.\nSecondly, as part of the block processor overhaul, the @block_processor decorator had breaking changes without backward-compatible deprecation. I am not aware of any third-party code actually using it, so this shouldn\u0026rsquo;t cause any issue.\nWhat\u0026rsquo;s next? Congrats if you got this far! 😲🏆\nI hope you\u0026rsquo;ll enjoy vpype 1.9 as much as I sweated preparing it. 😅\nFeedback is welcome, via discussions for support/suggestions or issues for bugs. As always, I hang out on the drawingbots.net\u0026rsquo;s Discord server and am available for a chat.\nContributions are most welcome too, and the documentation is one area where help is always beneficial. I\u0026rsquo;ve gathered a few ideas of what can be done here.\nTo conclude, here are my probable areas of focus for the coming weeks/months:\n Given the scope of this release, I\u0026rsquo;m expecting to deal with increased user support and a few kirks and bugs to address. I\u0026rsquo;ll be available for this in the short term. Property-related stuff must be ported to vsketch, including a nice API to set layer name, color, pen-width, etc. The next big topic for vpype is its UX. At least, I want to improve the look and usability of the integrated help (using the brand new rich-click project), and add some visual feedback during execution. With support for Python 3.7 dropped, compatibility with Python 3.10 is now on the menu. Whatever user feedback might steer my attention to 😉  ","permalink":"https://bylr.info/articles/2022/03/03/annotated-release-notes-vpype-1.9/","summary":"vpype \\ text -l1 -p 0 3.5cm \"Custom layer name/color/pen width\" \\ text -l2 -p 5cm 4.5cm -s 24 \"Properties\" \\ text -l2 -p 2cm 5.5cm -s 20 \"Expressions\" \\ text -l1 -p 6cm 6.5cm -s 24 \"Better/new block processors\" \\ text -l2 -p 3cm 8cm \"...and much more!\" \\ layout -m 0.3cm -l 10x3.5cm \\ penwidth -l2 0.5mm \\ color -l2 \"%Color(226,200,0)%\" \\ color -l1 \"%Color(3,118,207)%\" \\ color -l1 blue \\ show -- vpype 1.","title":"Annotated Release Notes: vpype 1.9"},{"content":"Hello again, world.\nLately, I\u0026rsquo;ve been meaning to document some of my personal projects and endeavours, and realised that I lacked a suitable outlet. I figured this would be a great occasion to test Hugo and GitHub Pages, so here we are!\nThis is what might ramble about in the future:\n Stuff about vpype, vsketch, and my other plotter-related software projects. Logs for some of my past and future projects (plotter-related or otherwise). Posts related to Home Assistant or other home-automation topics. Who knows what else.  Follow me on Twitter for updates.\n","permalink":"https://bylr.info/articles/2022/02/20/first-post/","summary":"\u003cp\u003eHello again, world.\u003c/p\u003e","title":"First post"},{"content":"My name is Antoine Beyeler. I am a multi-disciplinary engineer and entrepreneur with a PhD in flying robotics and interests in software, aviation, photography, generative art, plotters, and home automation. I live in Lausanne, Switzerland 🇨🇭.\nWith a few friends, I co-founded senseFly in 2009, which soon became the leader of fixed-wing mapping drones for surveyors, farmers, humanitarians and many others. Until my departure in 2018, I lead as CTO a team of up to 45 engineers and developed multiple generations of end-to-end mapping drone systems. I am now involved in advisory capacity with several start-ups in the Geneva region.\nLike my skills, my contributions to generative art lean on the technical rather than the artistic side 👨‍💻. Among other things, I created and maintain two open-source projects for plotter generative artists:\n vpype: a Swiss-Army-knife CLI to generate, manage, process, and convert vector graphic files for plotters, vsketch: a Python plotter generative art framework and workflow automation tool.  When I am not at the computer, you may find me piloting a helicopter 🚁 or behind the camera 📷 on my travels.\nAbout this site This site is built using Hugo and the PaperMod theme. It is hosted on GitHub Pages and deployed using a simple GitHub Actions workflow. Privacy-friendly and GDPR-compliant analytics services are provided by Plausible (a paid service, so neither you or I are the product).\n","permalink":"https://bylr.info/about/","summary":"My name is Antoine Beyeler. I am a multi-disciplinary engineer and entrepreneur with a PhD in flying robotics and interests in software, aviation, photography, generative art, plotters, and home automation. I live in Lausanne, Switzerland 🇨🇭.\nWith a few friends, I co-founded senseFly in 2009, which soon became the leader of fixed-wing mapping drones for surveyors, farmers, humanitarians and many others. Until my departure in 2018, I lead as CTO a team of up to 45 engineers and developed multiple generations of end-to-end mapping drone systems.","title":"About"}]